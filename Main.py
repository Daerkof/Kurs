import librosa
import numpy as np
import matplotlib.pyplot as plt
import soundfile as sf
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
import os
import streamlit as st
import sounddevice as sd
import tempfile
import joblib

# === 1. –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è –æ–∑–Ω–∞–∫ ===
def extract_features(file_path, target_sr=22050):
    y, sr = librosa.load(file_path, sr=target_sr)
    y = librosa.util.normalize(y)
    mfcc = librosa.feature.mfcc(y=y, sr=target_sr, n_mfcc=13)
    mfcc_mean = np.mean(mfcc.T, axis=0)
    return mfcc_mean

# === 2. –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –¥–æ–¥–∞–≤–∞–Ω–Ω—è —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è —à—É–º—É ===
def add_noise(y, noise_level=0.005):
    noise = np.random.randn(len(y))
    return y + noise_level * noise



# === 3. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞—Ç–∞—Å–µ—Ç—É ===
def load_dataset(folder):
    features = []
    labels = []
    for label in os.listdir(folder):
        class_folder = os.path.join(folder, label)
        if not os.path.isdir(class_folder):
            continue
        for file in os.listdir(class_folder):
            if file.endswith(".wav"):
                file_path = os.path.join(class_folder, file)
                y, sr = librosa.load(file_path, sr=22050)
                y = librosa.util.normalize(y)

                # –∑–≤–∏—á–∞–π–Ω—ñ –æ–∑–Ω–∞–∫–∏
                mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
                mfcc_mean = np.mean(mfcc.T, axis=0)
                features.append(mfcc_mean)
                labels.append(label)

                # –∞—É–≥–º–µ–Ω—Ç–æ–≤–∞–Ω—ñ –æ–∑–Ω–∞–∫–∏ (–∑—ñ —à—É–º–æ–º)
                y_noisy = add_noise(y)
                mfcc_noisy = librosa.feature.mfcc(y=y_noisy, sr=sr, n_mfcc=13)
                mfcc_noisy_mean = np.mean(mfcc_noisy.T, axis=0)
                features.append(mfcc_noisy_mean)
                labels.append(label)
    return np.array(features), np.array(labels)


# === 4. –ù–∞–≤—á–∞–Ω–Ω—è —Ç–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ ===
def train_model(dataset_path="dataset"):
    X, y = load_dataset(dataset_path)
    le = LabelEncoder()
    y_encoded = le.fit_transform(y)
    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)
    model = RandomForestClassifier(n_estimators=100)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    joblib.dump(model, "sound_model.pkl")
    joblib.dump(le, "label_encoder.pkl")
    return classification_report(y_test, y_pred, target_names=le.classes_), confusion_matrix(y_test, y_pred)

# === 5. –ó–∞–ø–∏—Å –∑–≤—É–∫—É –∑ –º—ñ–∫—Ä–æ—Ñ–æ–Ω–∞ ===
def record_audio(duration=3, sr=22050):
    st.info(f"–ó–∞–ø–∏—Å –∑–≤—É–∫—É ({duration} —Å–µ–∫—É–Ω–¥)...")
    audio = sd.rec(int(duration * sr), samplerate=sr, channels=1)
    sd.wait()
    audio = audio.flatten()
    audio = librosa.util.normalize(audio)
    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
    sf.write(temp_file.name, audio, sr, subtype='PCM_16')
    return temp_file.name


# === 6. –ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è –∑–≤—É–∫—É ===
def classify_audio(file_path):
    model = joblib.load("sound_model.pkl")
    le = joblib.load("label_encoder.pkl")
    features = extract_features(file_path).reshape(1, -1)
    pred = model.predict(features)
    label = le.inverse_transform(pred)[0]
    return label

# === 7. –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∏ ===
def plot_spectrogram(file_path):
    y, sr = librosa.load(file_path, sr=None)
    S = librosa.feature.melspectrogram(y=y, sr=sr)
    S_DB = librosa.power_to_db(S, ref=np.max)
    fig, ax = plt.subplots()
    img = librosa.display.specshow(S_DB, sr=sr, x_axis='time', y_axis='mel', ax=ax)
    ax.set(title='–ú–µ–ª-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∞')
    fig.colorbar(img, ax=ax, format='%+2.0f dB')
    return fig

# === 8. –Ü–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ (Streamlit) ===
st.set_page_config(page_title="–ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ç–æ—Ä –∑–≤—É–∫—ñ–≤", layout="centered")
st.title("üîä Sound Source Classifier")
st.write("–¶—è —Å–∏—Å—Ç–µ–º–∞ –¥–æ–∑–≤–æ–ª—è—î —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞—Ç–∏ –¥–∂–µ—Ä–µ–ª–∞ –∑–≤—É–∫—É: –º–æ–≤–∞, –º—É–∑–∏–∫–∞, —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç, –ø—Ä–∏—Ä–æ–¥–∞ —Ç–æ—â–æ.")

option = st.sidebar.radio("–û–±–µ—Ä—ñ—Ç—å –¥—ñ—é:", ["–ö–ª–∞—Å–∏—Ñ—ñ–∫—É–≤–∞—Ç–∏ –∞—É–¥—ñ–æ—Ñ–∞–π–ª", "–ó–∞–ø–∏—Å–∞—Ç–∏ —Ç–∞ –∫–ª–∞—Å–∏—Ñ—ñ–∫—É–≤–∞—Ç–∏ –∑–≤—É–∫", "–ù–∞–≤—á–∏—Ç–∏ –º–æ–¥–µ–ª—å"])

if option == "–ö–ª–∞—Å–∏—Ñ—ñ–∫—É–≤–∞—Ç–∏ –∞—É–¥—ñ–æ—Ñ–∞–π–ª":
    uploaded_file = st.file_uploader("–ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ WAV-—Ñ–∞–π–ª", type=["wav"])
    if uploaded_file is not None:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp:
            temp.write(uploaded_file.read())
            label = classify_audio(temp.name)
            st.success(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó: {label}")
            st.pyplot(plot_spectrogram(temp.name))

elif option == "–ó–∞–ø–∏—Å–∞—Ç–∏ —Ç–∞ –∫–ª–∞—Å–∏—Ñ—ñ–∫—É–≤–∞—Ç–∏ –∑–≤—É–∫":
    if st.button("üéôÔ∏è –ó–∞–ø–∏—Å–∞—Ç–∏ –∑–≤—É–∫"):
        file_path = record_audio()
        label = classify_audio(file_path)
        st.success(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó: {label}")
        st.pyplot(plot_spectrogram(file_path))

elif option == "–ù–∞–≤—á–∏—Ç–∏ –º–æ–¥–µ–ª—å":
    st.info("–í–∫–∞–∂—ñ—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—é –∑ –ø—ñ–¥–ø–∞–ø–∫–∞–º–∏-–∫–ª–∞—Å–∞–º–∏ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥: dataset/transport, dataset/speech)")
    dataset_path = st.text_input("üìÇ –®–ª—è—Ö –¥–æ –¥–∞—Ç–∞—Å–µ—Ç—É:", value="dataset")
    if st.button("üöÄ –ü–æ—á–∞—Ç–∏ –Ω–∞–≤—á–∞–Ω–Ω—è"):
        with st.spinner("–ù–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ..."):
            try:
                report, cm = train_model(dataset_path)
                st.success("–ú–æ–¥–µ–ª—å —É—Å–ø—ñ—à–Ω–æ –Ω–∞–≤—á–µ–Ω–∞!")
                st.text("üìä –ó–≤—ñ—Ç –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó:")
                st.text(report)
                st.text("–ú–∞—Ç—Ä–∏—Ü—è –ø–ª—É—Ç–∞–Ω–∏–Ω–∏:")
                st.text(str(cm))
            except Exception as e:
                st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –Ω–∞–≤—á–∞–Ω–Ω—è: {str(e)}")

# === 9. –î–æ–¥–∞—Ç–∫–æ–≤—ñ –≤–∫–∞–∑—ñ–≤–∫–∏ ===
st.sidebar.markdown("---")
st.sidebar.markdown("**–Ü–Ω—Å—Ç—Ä—É–∫—Ü—ñ—ó:**")
st.sidebar.markdown("1. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç—É –ø–æ–≤–∏–Ω–Ω–∞ –º–∞—Ç–∏ –ø—ñ–¥–ø–∞–ø–∫–∏ –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –∫–ª–∞—Å—É.")
st.sidebar.markdown("2. –§–∞–π–ª–∏ –ø–æ–≤–∏–Ω–Ω—ñ –±—É—Ç–∏ —É —Ñ–æ—Ä–º–∞—Ç—ñ WAV.")
st.sidebar.markdown("3. –ù–∞—Ç–∏—Å–Ω—ñ—Ç—å '–ù–∞–≤—á–∏—Ç–∏ –º–æ–¥–µ–ª—å', —â–æ–± –∑–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ç–æ—Ä.")
